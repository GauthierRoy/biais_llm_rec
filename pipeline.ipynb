{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "\n",
    "# json import music from music.jyson\n",
    "dataset_type = \"college\"\n",
    "with open('data/datasets/college_small.json', 'r') as f:\n",
    "    items = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_inf import OllamaClient, VLLMClient\n",
    "USE_OLLAMA = False # Set to True if using Ollama, False for vLLM\n",
    "model_name = \"google/gemma-3-4b-it\" # Model name for Ollama or vLLM\n",
    "if USE_OLLAMA:\n",
    "    # Configure Ollama options if needed\n",
    "    ollama_options = {'temperature': 0.7} # Example option\n",
    "    llm_client = OllamaClient(ollama_options=ollama_options)\n",
    "    print(f\"Using Ollama backend with model: {model_name}\")\n",
    "else:\n",
    "    # Configure VLLM connection details\n",
    "    # You need to do this command in terminal to start the vLLM server:\n",
    "    #  python -m vllm.entrypoints.openai.api_server --model=\"google/gemma-3-4b-it\"\n",
    "    # python -m vllm.entrypoints.openai.api_server --model=\"google/gemma-3-4b-it\" --max-model-len 50000\n",
    "    vllm_base_url = \"http://localhost:8000/v1\" # Adjust if your vLLM server is elsewhere\n",
    "    vllm_api_key = \"dummy\" # Usually 'dummy' or 'no-key' for local vLLM\n",
    "    # Configure generation parameters for vLLM if needed\n",
    "    vllm_client_options = {'temperature': 0.7, 'max_tokens': 1024} # Example options\n",
    "    llm_client = VLLMClient(base_url=vllm_base_url, api_key=vllm_api_key, client_options=vllm_client_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could also use model = \"llama2-uncensored\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from users import User\n",
    "\n",
    "from utils import extract_list_from_response\n",
    "from metrics import calc_iou, calc_serp_ms, calc_prag\n",
    "\n",
    "dataset_type = \"college\"\n",
    "k=20\n",
    "type_of_activity = \"student\"\n",
    "\n",
    "neutral_user = User(dataset_type=dataset_type, items=items, k=k, type_of_activity=type_of_activity, sensitive_atribute=\"a\")\n",
    "\n",
    "prompts = neutral_user.build_prompts()\n",
    "response = llm_client.chat(model=model_name, messages=prompts)\n",
    "neutral_list = extract_list_from_response(response)\n",
    "print(f\"Neutral attribute:\")\n",
    "print(f\"Recommended list: {neutral_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "with open('data/sensitive_atributes.json', 'r') as f:\n",
    "    dict_sensitive_atributes = json.load(f)\n",
    "\n",
    "for type_of_sensitive_atributes in tqdm(dict_sensitive_atributes, desc=\"Processing sensitive attributes\", position=0):\n",
    "    sensitive_atributes = dict_sensitive_atributes[type_of_sensitive_atributes]\n",
    "    res = {}\n",
    "    for sensitive_atribute in tqdm(sensitive_atributes, desc=f\"Processing {type_of_sensitive_atributes}\", leave=False, position=1):\n",
    "        user = User(dataset_type=dataset_type, items=items, k=k, type_of_activity=type_of_activity, sensitive_atribute=sensitive_atribute)\n",
    "        prompts = user.build_prompts()\n",
    "        response = llm_client.chat(model=model_name, messages=prompts)\n",
    "        extracted_list = extract_list_from_response(response)\n",
    "        res[sensitive_atribute] = {\n",
    "            \"IOU\": calc_iou(neutral_list, extracted_list),\n",
    "            \"SERP MS\": calc_serp_ms(neutral_list, extracted_list),\n",
    "            \"Pragmatic\": calc_prag(neutral_list, extracted_list)\n",
    "        }\n",
    "    final_results[type_of_sensitive_atributes] = res\n",
    "\n",
    "file = f\"results_{model_name.replace('/', '_')}_{dataset_type}.json\" \n",
    "with open(file, 'w') as f:\n",
    "    json.dump(final_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for key, value in final_results.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "    df = pd.DataFrame(value)\n",
    "\n",
    "    df_reset = df.reset_index().rename(columns={\"index\": \"Metric\"})\n",
    "    df_long = df_reset.melt(id_vars=\"Metric\", var_name=key, value_name=\"Value\")\n",
    "\n",
    "    df_long[key] = df_long[key].str.replace(\"an |a \", \"\", regex=True).str.title()\n",
    "\n",
    "    df_long\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_long, x=key, y=\"Value\", hue=\"Metric\", palette=\"muted\")\n",
    "\n",
    "    plt.title(f\"Comparison of IOU, SERP MS, and Pragmatic Metrics by {key}\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_rank = {item:i for i, item in enumerate(items)}\n",
    "items_rank\n",
    "\n",
    "res = []\n",
    "for item in extracted_list:\n",
    "    item = item.split(\": \")[-1].strip()\n",
    "    rank = items_rank.get(item, 0)\n",
    "    if rank != 0:\n",
    "        res.append(rank)\n",
    "\n",
    "import numpy as np\n",
    "print(np.mean(res))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
